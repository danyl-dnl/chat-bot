{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danyl-dnl/chat-bot/blob/main/chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1iIgnq6gRJNz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e22b30a-57a5-44ea-d000-09475106041c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This script is designed for Google Colab. Please run the `run_interactive_chatbot_colab()` function from a Colab cell.\n",
            "Refer to the 'Example Usage in Colab' comments in the code.\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import json\n",
        "import os\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    API_KEY = userdata.get('GEMINI_API_KEY')\n",
        "    if not API_KEY:\n",
        "        print(\"Warning: GEMINI_API_KEY not found in Colab Secrets. Please add it.\")\n",
        "        print(\"Falling back to environment variable or empty string. API calls might fail.\")\n",
        "except ImportError:\n",
        "    API_KEY = os.getenv(\"GEMINI_API_KEY\", \"\")\n",
        "\n",
        "API_URL = \"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent\"\n",
        "\n",
        "chat_history = []\n",
        "\n",
        "def send_message_to_gemini(prompt: str):\n",
        "    global chat_history\n",
        "\n",
        "    chat_history.append({\"role\": \"user\", \"parts\": [{\"text\": prompt}]})\n",
        "\n",
        "    payload = {\n",
        "        \"contents\": chat_history,\n",
        "    }\n",
        "\n",
        "    headers = {\n",
        "        'Content-Type': 'application/json'\n",
        "    }\n",
        "\n",
        "    full_api_url = f\"{API_URL}?key={API_KEY}\"\n",
        "\n",
        "    print(\"Chatbot: Thinking...\")\n",
        "\n",
        "    try:\n",
        "        response = requests.post(full_api_url, headers=headers, data=json.dumps(payload))\n",
        "        response.raise_for_status()\n",
        "\n",
        "        result = response.json()\n",
        "\n",
        "        if result.get(\"candidates\") and len(result[\"candidates\"]) > 0 and \\\n",
        "           result[\"candidates\"][0].get(\"content\") and \\\n",
        "           result[\"candidates\"][0][\"content\"].get(\"parts\") and \\\n",
        "           len(result[\"candidates\"][0][\"content\"][\"parts\"]) > 0:\n",
        "            bot_response = result[\"candidates\"][0][\"content\"][\"parts\"][0][\"text\"]\n",
        "            chat_history.append({\"role\": \"model\", \"parts\": [{\"text\": bot_response}]})\n",
        "            display(Markdown(f\"**Chatbot:** {bot_response}\"))\n",
        "            return bot_response\n",
        "        else:\n",
        "            error_msg = \"An error occurred: Could not get a response from the model.\"\n",
        "            print(error_msg)\n",
        "            print(f\"Full API response: {json.dumps(result, indent=2)}\")\n",
        "            return error_msg\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        error_msg = f\"Error during API request: {e}\"\n",
        "        print(error_msg)\n",
        "        return error_msg\n",
        "    except json.JSONDecodeError as e:\n",
        "        error_msg = f\"Error decoding JSON response: {e}\"\n",
        "        print(error_msg)\n",
        "        return error_msg\n",
        "\n",
        "def run_interactive_chatbot_colab():\n",
        "    global chat_history\n",
        "    chat_history = []\n",
        "\n",
        "    print(\"--- Starting Interactive Gemini Chatbot Session ---\")\n",
        "    print(\"Chatbot: Hello! Ask me anything. Type 'exit' to end.\")\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"You: \").strip()\n",
        "\n",
        "        if user_input.lower() == 'exit':\n",
        "            print(\"Chatbot: Goodbye!\")\n",
        "            break\n",
        "\n",
        "        if not user_input:\n",
        "            continue\n",
        "\n",
        "        send_message_to_gemini(user_input)\n",
        "        print(\"-\" * 30)\n",
        "\n",
        "    print(\"--- End of Interactive Chatbot Session ---\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"This script is designed for Google Colab. Please run the `run_interactive_chatbot_colab()` function from a Colab cell.\")\n",
        "    print(\"Refer to the 'Example Usage in Colab' comments in the code.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WihyksEpRMJ-",
        "outputId": "a6ae45af-afff-45fc-9735-3a2f6855c73e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting Interactive Gemini Chatbot Session ---\n",
            "Chatbot: Hello! Ask me anything. Type 'exit' to end.\n"
          ]
        }
      ],
      "source": [
        "run_interactive_chatbot_colab()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}